{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Praneet weapon_detection_BL.ipynb","provenance":[{"file_id":"1FVHDv7jVLdfNlu-YzykdKNeplFwKGkkA","timestamp":1586446972679},{"file_id":"https://github.com/AlaaSenjab/-Tutorial-Tensorflow_Object_Detection_API_On_Custom_Dataset/blob/master/weapon_detection_BL.ipynb","timestamp":1586159848401}],"collapsed_sections":["sOcbTFEiPBKA","pOfuwfPrPSMz","A_tyvKnBP6qD","t9C3L_r4Pi6m","xMckMSJqFMyc","8vAGvftxHu8K","IuJcAPZFIfu7","RPN8liiQc7Ue"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3vrSwr9lmjdl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"outputId":"86edaf83-6c28-4d41-9eff-68ae7aef738a","executionInfo":{"status":"ok","timestamp":1586447168861,"user_tz":-330,"elapsed":47660,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ubUsE7qtMWfj","colab_type":"text"},"source":["\n","### **Inroduction**:\n","\n","\n","Aiming to minimize police response time by detecting weapons in a live cctv camera. The main motivation of this project is due to the increasing number of school mass shootings in the U.S.\n","\n","\n","### This notebook is a part of this [medium post](https://medium.com/@alaasinjab/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d)."]},{"cell_type":"markdown","metadata":{"id":"Yi0JMo0RNT2Y","colab_type":"text"},"source":["### This notebook was designed to be ran from top to bottom without the need to mount Google Drive"]},{"cell_type":"markdown","metadata":{"id":"65t7YUhnzDCE","colab_type":"text"},"source":["## Weapon Detection Using Tensorflow Object Detection API"]},{"cell_type":"markdown","metadata":{"id":"CWrRz3kXDksW","colab_type":"text"},"source":["Workspace structure\n","\n","```\n","gun_detection/\n","        ├─ data/\n","        │    ├── images/\n","        │    │      ├── armas (1).jpg\n","        │    │      ├── armas (2).jpg\n","        │    │      └── ...\n","        │    ├── train_labels/\n","        │    │      ├── armas (1).xml\n","        │    │      ├── armas (2).xml\n","        │    │      └── ...\n","        │    ├── test_labels/\n","        │    │      ├── armas (10).xml\n","        │    │      ├── armas (20).xml\n","        │    │      └── ...\n","        │    ├── label_map.pbtxt\n","        │    ├── test_labels.csv\n","        │    ├── train_labels.csv\n","        │    ├── test_labels.record\n","        │    └── train_labels.record\n","        └─ models/\n","             ├─ research/\n","             │      ├── fine_tuned_model/\n","             │      │         ├── frozen_inference_graph.pb\n","             │      │         └── ...\n","             │      │         \n","             │      ├── pretrained_model/\n","             │      │         ├── frozen_inference_graph.pb\n","             │      │         └── ...\n","             │      │         \n","             │      ├── object_detection/\n","             │      │         ├── utils/\n","             │      │         ├── samples/\n","             │      │         │      ├── samples/ \n","             │      │         │      │       ├── configs/             \n","             │      │         │      │       │     ├── ssd_mobilenet_v2_coco.config\n","             │      │         │      │       │     ├── rfcn_resnet101_pets.config\n","             │      │         │      │       │     └── ...\n","             │      │         │      │       └── ... \n","             │      │         │      └── ...                                \n","             │      │         ├── export_inference_graph.py\n","             │      │         ├── model_main.py\n","             │      │         └── ...\n","             │      │         \n","             │      ├── training/\n","             │      │         ├── events.out.tfevents.xxxxx\n","             │      │         └── ...               \n","             │      └── ...\n","             └── ...\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AMlXJ2yIV8e7","colab_type":"text"},"source":["## Choosing a pre training model\n","The model used for this project is `ssd_mobilenet_v2_coco`.\n","Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n","\n","Because the interestes of this project is to interfere on real time video, i am chosing a model that has a high inference speed `(ms)` with relativly high `mAP` on COCO"]},{"cell_type":"code","metadata":{"id":"j3_Ns54i3HgO","colab_type":"code","colab":{}},"source":["\n","\n","# Some models to train on\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","    }\n","}\n","\n","# Select a model in `MODELS_CONFIG`.\n","# I chose ssd_mobilenet_v2 for this project, you could choose any\n","selected_model = 'ssd_mobilenet_v2'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sv3Zm042QGJy","colab_type":"text"},"source":["## Installing Required Packages "]},{"cell_type":"code","metadata":{"id":"68StUELaQPS2","colab_type":"code","outputId":"a49e75dc-839f-447c-d045-aaece610f407","executionInfo":{"status":"ok","timestamp":1586447338378,"user_tz":-330,"elapsed":139493,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -qq pycocotools\n","\n","!pip install tensorflow==1.15.0rc1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package python-bs4.\n","(Reading database ... 144568 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Collecting tensorflow==1.15.0rc1\n","\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/50/36/f937111a86260b52b743ff0eda9b10aec20faa93ac7806728b2db545d1cb/tensorflow-1.15.0rc1-cp36-cp36m-manylinux2010_x86_64.whl\u001b[0m\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/36/f937111a86260b52b743ff0eda9b10aec20faa93ac7806728b2db545d1cb/tensorflow-1.15.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (412.0MB)\n","\u001b[K     |████████████████████████████████| 412.0MB 39kB/s \n","\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 49.7MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.12.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (0.9.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.0.8)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (0.8.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (3.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.27.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (0.2.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (3.10.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.18.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (0.34.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0rc1) (1.1.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 56.3MB/s \n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc1) (3.2.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc1) (46.1.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0rc1) (2.10.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=beb43c419a18a423439b6577f5c56a81e1f32f556b7a7185e7a5d13183288a88\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.2.0\n","    Uninstalling tensorboard-2.2.0:\n","      Successfully uninstalled tensorboard-2.2.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.2.0rc0\n","    Uninstalling tensorflow-estimator-2.2.0rc0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n","  Found existing installation: tensorflow 2.2.0rc2\n","    Uninstalling tensorflow-2.2.0rc2:\n","      Successfully uninstalled tensorflow-2.2.0rc2\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0rc1 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ERyocH9U-o2Y","colab_type":"text"},"source":["## General imports\n","Other Imports will be done after downloading some packages later."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ab_Wzt0oFNbe","outputId":"7e648cca-edf2-4c1e-9eee-82829b739fd3","executionInfo":{"status":"ok","timestamp":1586447458015,"user_tz":-330,"elapsed":12080,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":271}},"source":["!pip install PyDrive"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n","Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (46.1.3)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CEVLeKXh-s23","colab_type":"code","outputId":"a3fbb42d-4d4a-4b8a-8346-10fc6f2a1d76","executionInfo":{"status":"ok","timestamp":1586447470039,"user_tz":-330,"elapsed":5700,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":79}},"source":["from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import cv2 \n","import os\n","import glob\n","import xml.etree.ElementTree as ET\n","\n","import io\n","import tensorflow.compat.v1 as tf\n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","import shutil\n","import urllib.request\n","import tarfile\n","\n","from google.colab import files\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Y8QeHvX6gpmC","colab_type":"code","outputId":"c4ccbc75-fe47-4441-c98f-c733a6e66a6b","executionInfo":{"status":"ok","timestamp":1586447478240,"user_tz":-330,"elapsed":4038,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["#we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n","print(tf.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1.15.0-rc1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSAGGELkDpeG","colab_type":"code","colab":{}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zXlyjlGEGyj","colab_type":"code","colab":{}},"source":["downloaded = drive.CreateFile({'id':\"1_frhMOnYFW9I7HxyYEIwinlSiDLyvk7j\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('label_map.pbtxt')        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQ6OzoRoEsu_","colab_type":"code","outputId":"7f35d493-f354-46ff-f0a6-305faf450d5d","executionInfo":{"status":"ok","timestamp":1586236682899,"user_tz":-330,"elapsed":1779,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloaded content \"item {\r\n","  id: 1\r\n","  name: 'Pistols'\r\n","}\r\n","\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"60iIO7CwEzw3","colab_type":"code","colab":{}},"source":["downloaded = drive.CreateFile({'id':\"19kcrS0FRFSKvxyxmvPSHQdpje5WpVLD_\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('train.record')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmZgp2dwFDed","colab_type":"code","colab":{}},"source":["ownloaded = drive.CreateFile({'id':\"19kcrS0FRFSKvxyxmvPSHQdpje5WpVLD_\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('test.record')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sOcbTFEiPBKA","colab_type":"text"},"source":["## Downloading and Orgniazing Images and Annotations\n","1. Downloading the images and annotations from the [source](https://sci2s.ugr.es/weapons-detection)  and unziping them\n","2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n","3. Creating two directories; for the training and testing labels (not the images)\n","4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "]},{"cell_type":"code","metadata":{"id":"2QY-CyUQwyZr","colab_type":"code","colab":{}},"source":["#creates a directory for the whole project\n","!mkdir gun_detection"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHPQQmhm7RLe","colab_type":"code","outputId":"3aa7bf32-cad3-42d4-f2f6-078f5e1a1990","executionInfo":{"status":"ok","timestamp":1586447684409,"user_tz":-330,"elapsed":3173,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["cd gun_detection"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/gun_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tp62o3a07UbP","colab_type":"code","outputId":"e1c95a81-2aa4-46a4-c131-049838d7a928","executionInfo":{"status":"error","timestamp":1586169681731,"user_tz":-330,"elapsed":51471,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["#Training images and annotations\n","\n","#Source: https://sci2s.ugr.es/weapons-detection\n","\n","\n","#download the images zip\n","!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n","\n","#unzip the image file\n","!unzip -q WeaponS.zip\n","\n","#download the annotations zip\n","!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n","\n","#unzip the annotations file\n","!unzip -q WeaponS_bbox.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-04-06 16:10:31--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n","Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n","Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 250005059 (238M) [application/zip]\n","Saving to: ‘WeaponS.zip’\n","\n","WeaponS.zip         100%[===================>] 238.42M  11.1MB/s    in 22s     \n","\n","2020-04-06 16:10:54 (10.9 MB/s) - ‘WeaponS.zip’ saved [250005059/250005059]\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-ef3a1cc42317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#unzip the image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip -q WeaponS.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#download the annotations zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"L0czMMeR8GxW","colab_type":"code","outputId":"4b83523d-69fd-41f2-9f2d-7cd46c6e3e9d","executionInfo":{"status":"ok","timestamp":1586447850047,"user_tz":-330,"elapsed":42360,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# creating a directory to store the training and testing data\n","!mkdir data\n","\n","# folders for the training and testing data.\n","!mkdir data/images data/train_labels data/test_labels\n","\n","\n","# combining the images and annotation in the training folder:\n","# moves the images to data folder\n","!mv WeaponS/* data/images\n","\n","# moves the annotations to data folder\n","!mv WeaponS_bbox/* data/train_labels"],"execution_count":11,"outputs":[{"output_type":"stream","text":["mv: cannot stat 'WeaponS/*': No such file or directory\n","mv: cannot stat 'WeaponS_bbox/*': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vv8pmB2D80M7","colab_type":"code","colab":{}},"source":["# Deleting the zipped and unzipped folders \n","!rm -rf WeaponS_bbox.zip  WeaponS.zip WeaponS/  WeaponS_bbox/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUl-XRwPvj4j","colab_type":"code","colab":{}},"source":["\n","# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n","# Moves the first 600 labels to the testing dir: `test_labels`\n","!ls data/train_labels/* | sort -R | head -600 | xargs -I{} mv {} data/test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmvDu-rUHz96","colab_type":"code","colab":{}},"source":["# 2400 \"images\"(xml) for training\n","ls -1 data/train_labels/ | wc -l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8y-1_t7wRJc","colab_type":"code","outputId":"d3fbc256-3907-4249-f4c6-97dcb90a3fde","executionInfo":{"status":"ok","timestamp":1586169106315,"user_tz":-330,"elapsed":5274,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 600 \"images\"(xml) for testing\n","ls -1 data/test_labels/ | wc -l"],"execution_count":0,"outputs":[{"output_type":"stream","text":["600\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pOfuwfPrPSMz","colab_type":"text"},"source":["## Preprocessing Images and Labels\n","1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n","2. Creating a pbtxt file that specifies the number of class (one class in this case)\n","3. Checking if the annotations for each object are placed within the range of the image width and height."]},{"cell_type":"code","metadata":{"id":"TBHBFpWyEIDI","colab_type":"code","outputId":"9f1d286b-c44f-4aa6-85af-84c2fc47b9b8","executionInfo":{"status":"ok","timestamp":1586169315231,"user_tz":-330,"elapsed":1296,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","\n","#converts the annotations/labels into one csv file for each training and testing labels\n","#creats label_map.pbtxt file\n","\n","%cd /content/drive/'My Drive'/object_detection/gun_detection/data\n","\n","\n","# images extension\n","images_extension = 'jpg'\n","\n","# takes the path of a directory that contains xml files and converts\n","#  them to one csv file.\n","\n","# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n","# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text + '.' + images_extension,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","# Creating the `label_map.pbtxt` file\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","\n","pbtxt_content = \"\"\n","\n","#creats a pbtxt file the has the class names.\n","for i, class_name in enumerate(classes):\n","    # display_name is optional.\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'Gun'\\n }}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/My Drive/object_detection/gun_detection/data'\n","/content/drive/My Drive/object_detection\n","Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rtfjZcD-CCdM","colab_type":"code","colab":{}},"source":["#checking the pbtxt file\n","!cat label_map.pbtxt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yP8gohagKFXn","colab_type":"code","outputId":"3893e11d-ca7c-4994-fa35-cbf312886de4","executionInfo":{"status":"ok","timestamp":1586169329203,"user_tz":-330,"elapsed":4821,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# they are there!\n","ls -l"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 17\n","drwx------ 5 root root 4096 Apr  6 16:00 \u001b[0m\u001b[01;34mdata\u001b[0m/\n","drwx------ 2 root root 4096 Apr  6 15:56 \u001b[01;34mgun_detection\u001b[0m/\n","-rw------- 1 root root    0 Apr  6 16:05 label_map.pbtxt\n","drwx------ 3 root root 4096 Apr  6 15:58 \u001b[01;34m__MACOSX\u001b[0m/\n","-rw------- 1 root root   48 Apr  6 16:05 test_labels.csv\n","drwx------ 2 root root 4096 Apr  6 15:52 \u001b[01;34mtraining\u001b[0m/\n","-rw------- 1 root root   48 Apr  6 16:05 train_labels.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L4p7J6mFLLZf","colab_type":"code","outputId":"a8fcdd17-17f5-4401-c89e-758d17e8c3df","executionInfo":{"status":"ok","timestamp":1586169373657,"user_tz":-330,"elapsed":2579,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#checks if the images box position is placed within the image.\n","\n","#note: while this doesn't checks if the boxes/annotatoins are correctly\n","# placed around the object, Tensorflow will through an error if this occured.\n","%cd /content/drive/'My Drive'/object_detection/gun_detection/data\n","# path to images\n","images_path = 'images'\n","\n","#loops over both train_labels and test_labels csv files to do the check\n","# returns the image name where an error is found \n","# return the incorrect attributes; xmin, ymin, xmax, ymax.\n","for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n","  with open(CSV_FILE, 'r') as fid:  \n","      print('[*] Checking file:', CSV_FILE) \n","      file = csv.reader(fid, delimiter=',')\n","      first = True \n","      cnt = 0\n","      error_cnt = 0\n","      error = False\n","      for row in file:\n","          if error == True:\n","              error_cnt += 1\n","              error = False         \n","          if first == True:\n","              first = False\n","              continue     \n","          cnt += 1      \n","          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n","          path = os.path.join(images_path, name)\n","          img = cv2.imread(path)         \n","          if type(img) == type(None):\n","              error = True\n","              print('Could not read image', img)\n","              continue     \n","          org_height, org_width = img.shape[:2]     \n","          if org_width != width:\n","              error = True\n","              print('Width mismatch for image: ', name, width, '!=', org_width)     \n","          if org_height != height:\n","              error = True\n","              print('Height mismatch for image: ', name, height, '!=', org_height) \n","          if xmin > org_width:\n","              error = True\n","              print('XMIN > org_width for file', name)  \n","          if xmax > org_width:\n","              error = True\n","              print('XMAX > org_width for file', name)\n","          if ymin > org_height:\n","              error = True\n","              print('YMIN > org_height for file', name)\n","          if ymax > org_height:\n","              error = True\n","              print('YMAX > org_height for file', name)\n","          if error == True:\n","              print('Error for file: %s' % name)\n","              print()\n","      print()\n","      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n","      print(\"-----\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/My Drive/object_detection/gun_detection/data'\n","/content/drive/My Drive/object_detection\n","[*] Checking file: train_labels.csv\n","\n","Checked 0 files and realized 0 errors\n","-----\n","[*] Checking file: test_labels.csv\n","\n","Checked 0 files and realized 0 errors\n","-----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vD5luKTsMx7F","colab_type":"code","colab":{}},"source":["#we have only one image with incorrect box position, we could just remove it \n","#removing the image \n","rm images/'armas (2815).jpg'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ze4z9bW3ZjhC","colab_type":"code","colab":{}},"source":["#removing the entry for it in the csv for that image as well\n","\n","#because we did a random split for the data, we dont know if it ended up being in training or testing\n","# we will remove the image from both.\n","\n","#training\n","#reading the training csv\n","df = pd.read_csv('/content/gun_detection/data/train_labels.csv')\n","# removing armas (2815).jpg\n","df = df[df['filename'] != 'armas (2815).jpg']\n","#reseting the index\n","df.reset_index(drop=True, inplace=True)\n","#saving the df\n","df.to_csv('/content/gun_detection/data/train_labels.csv')\n","\n","\n","#testing\n","#reading the testing csv\n","df = pd.read_csv('/content/gun_detection/data/test_labels.csv')\n","# removing armas (2815).jpg\n","df = df[df['filename'] != 'armas (2815).jpg']\n","#reseting the index\n","df.reset_index(drop=True, inplace=True)\n","#saving the df\n","df.to_csv('/content/gun_detection/data/test_labels.csv')\n","\n","# Just for the memory\n","df = None\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A_tyvKnBP6qD","colab_type":"text"},"source":["## Downloading and Preparing Tensorflow model\n","1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n","2. Compiling the protos and adding folders to the os environment.\n","3. Testing the model builder."]},{"cell_type":"code","metadata":{"id":"IIxz1GqJQA3f","colab_type":"code","outputId":"09bebd87-d737-48c5-e64a-c81bace88c8a","executionInfo":{"status":"ok","timestamp":1586447948798,"user_tz":-330,"elapsed":31880,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["# Downlaods Tenorflow\n","%cd /content/gun_detection/\n","!git clone --q https://github.com/tensorflow/models.git"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content/gun_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tjcAhsxRQ5N1","colab_type":"code","outputId":"f0c22788-12c1-4761-937f-3fc0a9db5a7e","executionInfo":{"status":"ok","timestamp":1586448017698,"user_tz":-330,"elapsed":4865,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["%cd /content/gun_detection/models/research\n","#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n","os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3bMNsrwTSJi2","colab_type":"code","outputId":"f52d2743-9b0a-4eaf-9808-c52898013951","executionInfo":{"status":"ok","timestamp":1586448029354,"user_tz":-330,"elapsed":7080,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":803}},"source":["# testing the model builder\n","!python3 object_detection/builders/model_builder_test.py"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_experimental_model\n","[       OK ] ModelBuilderTest.test_create_experimental_model\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 17 tests in 0.171s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t9C3L_r4Pi6m","colab_type":"text"},"source":["## Generating Tf record\n","- Generating two TFRecords files for the training and testing CSVs.\n","- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"]},{"cell_type":"code","metadata":{"id":"nK2unk-9LB_E","colab_type":"code","outputId":"7ef4c57a-4ad4-45f3-94d0-eb7e543eaa30","executionInfo":{"status":"ok","timestamp":1586160639222,"user_tz":-330,"elapsed":7347,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#adjusted from: https://github.com/datitran/raccoon_dataset\n","\n","# converts the csv files for training and testing data to two TFRecords files.\n","# places the output in the same directory as the input\n","\n","\n","from object_detection.utils import dataset_util\n","%cd /content/gun_detection/models/\n","\n","DATA_BASE_PATH = '/content/gun_detection/data/'\n","image_dir = DATA_BASE_PATH +'images/'\n","\n","def class_text_to_int(row_label):\n","\t\tif row_label == 'pistol':\n","\t\t\t\treturn 1\n","\t\telse:\n","\t\t\t\tNone\n","\n","\n","def split(df, group):\n","\t\tdata = namedtuple('data', ['filename', 'object'])\n","\t\tgb = df.groupby(group)\n","\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","def create_tf_example(group, path):\n","\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","\t\t\t\tencoded_jpg = fid.read()\n","\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n","\t\timage = Image.open(encoded_jpg_io)\n","\t\twidth, height = image.size\n","\n","\t\tfilename = group.filename.encode('utf8')\n","\t\timage_format = b'jpg'\n","\t\txmins = []\n","\t\txmaxs = []\n","\t\tymins = []\n","\t\tymaxs = []\n","\t\tclasses_text = []\n","\t\tclasses = []\n","\n","\t\tfor index, row in group.object.iterrows():\n","\t\t\t\txmins.append(row['xmin'] / width)\n","\t\t\t\txmaxs.append(row['xmax'] / width)\n","\t\t\t\tymins.append(row['ymin'] / height)\n","\t\t\t\tymaxs.append(row['ymax'] / height)\n","\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n","\t\t\t\tclasses.append(class_text_to_int(row['class']))\n","\n","\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n","\t\t\t\t'image/height': dataset_util.int64_feature(height),\n","\t\t\t\t'image/width': dataset_util.int64_feature(width),\n","\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n","\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n","\t\t}))\n","\t\treturn tf_example\n","\n","for csv in ['train_labels', 'test_labels']:\n","  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n","  path = os.path.join(image_dir)\n","  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n","  grouped = split(examples, 'filename')\n","  for group in grouped:\n","      tf_example = create_tf_example(group, path)\n","      writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models\n","Successfully created the TFRecords: /content/gun_detection/data/train_labels.record\n","Successfully created the TFRecords: /content/gun_detection/data/test_labels.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i1zRJducWs-X","colab_type":"code","outputId":"b115283a-6094-4677-c8b7-91062b6f673f","executionInfo":{"status":"ok","timestamp":1586160647729,"user_tz":-330,"elapsed":4908,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# TFRecords are created\n","ls -lX /content/gun_detection/data/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 252508\n","drwxr-xr-x 2 root root    118784 Apr  6 13:39 \u001b[0m\u001b[01;34mimages\u001b[0m/\n","drwxr-xr-x 2 root root     24576 Apr  6 13:36 \u001b[01;34mtest_labels\u001b[0m/\n","drwxr-xr-x 2 root root    122880 Apr  6 13:36 \u001b[01;34mtrain_labels\u001b[0m/\n","-rw-r--r-- 1 root root     36458 Apr  6 13:39 test_labels.csv\n","-rw-r--r-- 1 root root    154223 Apr  6 13:39 train_labels.csv\n","-rw-r--r-- 1 root root        62 Apr  6 13:37 label_map.pbtxt\n","-rw-r--r-- 1 root root  50408544 Apr  6 13:40 test_labels.record\n","-rw-r--r-- 1 root root 207685610 Apr  6 13:40 train_labels.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xMckMSJqFMyc","colab_type":"text"},"source":["## Downloading the Base Model\n","1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n","2. Creating a dir to save the model while training."]},{"cell_type":"code","metadata":{"id":"UvN9Cw65FQzB","colab_type":"code","outputId":"6baa19c9-3b4f-417f-deb7-bd29ab17e736","executionInfo":{"status":"ok","timestamp":1586448240450,"user_tz":-330,"elapsed":8751,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["%cd /content/gun_detection/models/research\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#the distination folder where the model will be saved\n","fine_tune_dir = '/content/gun_detection/models/research/pretrained_model'\n","\n","#checks if the model has already been downloaded\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the file and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(fine_tune_dir)):\n","    shutil.rmtree(fine_tune_dir)\n","os.rename(MODEL, fine_tune_dir)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pbjXKVMmFk47","colab_type":"code","outputId":"15cbadc4-e462-4ba3-ce63-479f5d4cc0d7","executionInfo":{"status":"ok","timestamp":1586448277075,"user_tz":-330,"elapsed":21612,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":201}},"source":["#checking the content of the pretrained model.\n","# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n","!echo {fine_tune_dir}\n","!ls -alh {fine_tune_dir}"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models/research/pretrained_model\n","total 135M\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n","drwxr-xr-x 63 root   root  4.0K Apr  9 16:03 ..\n","-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n","-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n","-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HnjQgJZiGAcA","colab_type":"text"},"source":["## Configuring the Training Pipeline\n","1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n","2. Adding some Image augmentation.\n","3. Creating a directory to save the model at each checkpoint while training. "]},{"cell_type":"code","metadata":{"id":"az14XVo31Ujp","colab_type":"code","outputId":"21fbaf63-097c-4260-ba7b-cbc96bc5ea57","executionInfo":{"status":"ok","timestamp":1586448312448,"user_tz":-330,"elapsed":2028,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["\n","#the path to the folder containing all the sample config files\n","CONFIG_BASE = \"/content/gun_detection/models/research/object_detection/samples/configs/\"\n","\n","#path to the specified model's config file\n","model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n","model_pipline"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"VT3m6pbXpN_M","colab_type":"code","colab":{}},"source":["#check the sample config file that is provided by the tf model\n","#!cat /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kfsl5CsDGY3-","colab_type":"code","outputId":"cd5ddbeb-3d7b-4b8c-8aca-399eac4a9892","executionInfo":{"status":"ok","timestamp":1586449241179,"user_tz":-330,"elapsed":1564,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["#editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n","# any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here\n","\n","%%writefile {model_pipline}\n","model {\n","  ssd {\n","    num_classes: 1 # number of classes to be detected\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    # all images will be resized to the below W x H.\n","    image_resizer { \n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        #use_dropout: false\n","        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","            # weight: 0.00004\n","            weight: 0.001 # higher regularizition to counter overfitting\n","          }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            # weight: 0.00004\n","            weight: 0.001 # higher regularizition to counter overfitting\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000 \n","        iou_threshold: 0.95\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        \n","        #adjust this to the max number of objects per class. \n","        # ex, in my case, i have one pistol in most of the images.\n","        # . there are some images with more than one up to 16.\n","        max_detections_per_class: 16\n","        # max number of detections among all classes. I have 1 class only so\n","        max_total_detections: 16\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 16 # training batch size\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.003\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","\n","  #the path to the pretrained model. \n","  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000 \n","  \n","\n","  #data augmentaion is done here, you can remove or add more.\n","  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n","  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n","  \n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_adjust_contrast {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    #path to the training TFRecord\n","    input_path: \"/content/gun_detection/data/train.record\"\n","  }\n","  #path to the label map \n","  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n","  num_examples: 599\n","  # the number of images to disply in Tensorboard while training\n","  num_visualizations: 20\n","\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  #max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","      \n","    #path to the testing TFRecord\n","    input_path: \"/content/gun_detection/data/test.record\"\n","  }\n","  #path to the label map \n","  label_map_path:\"/content/gun_detection/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Overwriting /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EuXXZLVEG8sO","colab_type":"code","colab":{}},"source":["# where the model will be saved at each checkpoint while training \n","model_dir = 'training/'\n","\n","# Optionally: remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vAGvftxHu8K","colab_type":"text"},"source":["## Tensorboard\n","1. Downlaoding and unzipping Tensorboard\n","2. creating a link to visualize multiple graph while training.\n","\n","\n","notes: \n","  1. Tensorboard will not log any files until the training starts. \n","  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."]},{"cell_type":"code","metadata":{"id":"Z2ucxlc5HxHL","colab_type":"code","outputId":"47d7cd3c-6750-4522-9331-206f57eb9c55","executionInfo":{"status":"ok","timestamp":1586161263556,"user_tz":-330,"elapsed":8195,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["#downlaoding ngrok to be able to access tensorboard on google colab\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-04-06 13:50:57--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.5.204.126, 52.203.240.15, 34.225.195.115, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.5.204.126|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  14.4MB/s    in 0.9s    \n","\n","2020-04-06 13:50:58 (14.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-w9ufxr7IAdv","colab_type":"code","colab":{}},"source":["#the logs that are created while training \n","LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"idsi9zyNIIsr","colab_type":"code","outputId":"d635db5d-74e0-4584-c692-55298efe6d7b","executionInfo":{"status":"ok","timestamp":1586161277179,"user_tz":-330,"elapsed":5034,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#The link to tensorboard.\n","#works after the training starts.\n","\n","### note: if you didnt get a link as output, rerun this cell and the one above\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["http://74c1da55.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBbv83HNJTrj","colab_type":"code","outputId":"b542db6b-2702-4e0a-b3ad-d1e0ea09a56a","executionInfo":{"status":"ok","timestamp":1586237902057,"user_tz":-330,"elapsed":4418,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["ls -l\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 276\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[0m\u001b[01;34ma3c_blogpost\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34madversarial_crypto\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34madversarial_logit_pairing\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34madversarial_text\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34madv_imagenet_models\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mattention_ocr\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34maudioset\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mautoaugment\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mautoencoder\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34mbrain_coder\u001b[0m/\n","drwxr-xr-x 11 root   root   4096 Apr  7 05:26 \u001b[01;34mcognitive_mapping_and_planning\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34mcognitive_planning\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34mcompression\u001b[0m/\n","drwxr-xr-x  7 root   root   4096 Apr  7 05:26 \u001b[01;34mcvt_text\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mdeep_contextual_bandits\u001b[0m/\n","drwxr-xr-x  9 root   root   4096 Apr  7 05:26 \u001b[01;34mdeeplab\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mdeep_speech\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mdelf\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mdomain_adaptation\u001b[0m/\n","drwxr-xr-x  8 root   root   4096 Apr  7 05:26 \u001b[01;34mefficient-hrl\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mfeelvos\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mfivo\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mglobal_objectives\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mim2txt\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34minception\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mkeypointnet\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34mlearned_optimizer\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mlearning_to_remember_rare_events\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mlearning_unsupervised_learning\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mlexnet_nc\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mlfads\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mlm_1b\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mlm_commonsense\u001b[0m/\n","drwxr-xr-x 13 root   root   4096 Apr  7 05:26 \u001b[01;34mlstm_object_detection\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mmarco\u001b[0m/\n","drwxr-xr-x  8 root   root   4096 Apr  7 05:26 \u001b[01;34mmaskgan\u001b[0m/\n","-rw-r--r--  1 root   root   5711 Apr  7 05:29 {model_pipline}\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mnamignizer\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mneural_gpu\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mneural_programmer\u001b[0m/\n","drwxr-xr-x  4 root   root   4096 Apr  7 05:26 \u001b[01;34mnext_frame_prediction\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mnst_blogpost\u001b[0m/\n","drwxr-xr-x 26 root   root   4096 Apr  7 05:26 \u001b[01;34mobject_detection\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mpcl_rl\u001b[0m/\n","drwxr-xr-x  3 345018 89939  4096 Mar 30  2018 \u001b[01;34mpretrained_model\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mptn\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mqa_kg\u001b[0m/\n","-rw-r--r--  1 root   root  12648 Apr  7 05:26 README.md\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mreal_nvp\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mrebar\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34msentiment_analysis\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mseq2species\u001b[0m/\n","-rw-r--r--  1 root   root    446 Apr  7 05:26 setup.py\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mskip_thoughts\u001b[0m/\n","drwxr-xr-x  7 root   root   4096 Apr  7 05:26 \u001b[01;34mslim\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34msteve\u001b[0m/\n","drwxr-xr-x  6 root   root   4096 Apr  7 05:26 \u001b[01;34mstreet\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mstruct2depth\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mswivel\u001b[0m/\n","drwxr-xr-x  7 root   root   4096 Apr  7 05:26 \u001b[01;34mtcn\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mtextsum\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:32 \u001b[01;34mtraining\u001b[0m/\n","drwxr-xr-x  3 root   root   4096 Apr  7 05:26 \u001b[01;34mtransformer\u001b[0m/\n","drwxr-xr-x  5 root   root   4096 Apr  7 05:26 \u001b[01;34mvid2depth\u001b[0m/\n","drwxr-xr-x  2 root   root   4096 Apr  7 05:26 \u001b[01;34mvideo_prediction\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IuJcAPZFIfu7","colab_type":"text"},"source":["## Training\n","\n","Finally training the model!\n"]},{"cell_type":"code","metadata":{"id":"vnKt6g0_IgOe","colab_type":"code","outputId":"01803374-5158-4bc1-9daf-f4950364fb2e","executionInfo":{"status":"ok","timestamp":1586458485417,"user_tz":-330,"elapsed":676200,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","!python3 /content/gun_detection/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={model_pipline}\\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\"],"execution_count":42,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0409 18:43:36.869445 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0409 18:43:36.872519 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0409 18:43:36.872653 140615978522496 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0409 18:43:36.872745 140615978522496 config_util.py:488] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0409 18:43:36.872839 140615978522496 config_util.py:488] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0409 18:43:36.872937 140615978522496 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0409 18:43:36.873029 140615978522496 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0409 18:43:36.873116 140615978522496 config_util.py:488] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0409 18:43:36.873195 140615978522496 config_util.py:498] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0409 18:43:36.873829 140615978522496 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0409 18:43:36.873937 140615978522496 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe33da15a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0409 18:43:36.874336 140615978522496 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe33da15a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe33da0d488>) includes params argument, but params are not passed to Estimator.\n","W0409 18:43:36.874535 140615978522496 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe33da0d488>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0409 18:43:36.875356 140615978522496 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0409 18:43:36.875553 140615978522496 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0409 18:43:36.875787 140615978522496 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0409 18:43:36.884213 140615978522496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0409 18:43:36.894309 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0409 18:43:36.906063 140615978522496 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0409 18:43:36.912265 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0409 18:43:36.912423 140615978522496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0409 18:43:36.932559 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0409 18:43:44.610222 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0409 18:43:49.617377 140615978522496 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0409 18:43:52.657193 140615978522496 module_wrapper.py:137] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0409 18:43:53.021579 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","W0409 18:43:54.921736 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","INFO:tensorflow:Calling model_fn.\n","I0409 18:43:54.933545 140615978522496 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0409 18:43:55.140817 140615978522496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:43:57.498383 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:43:57.534433 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:43:57.571495 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:43:57.607382 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:43:57.642396 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:43:57.678052 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0409 18:43:57.719716 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0409 18:43:57.725529 140615978522496 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n","W0409 18:43:57.725734 140615978522496 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0409 18:43:57.725918 140615978522496 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0409 18:43:57.726060 140615978522496 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0409 18:44:00.873619 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0409 18:44:00.878918 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0409 18:44:03.135849 140615978522496 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","I0409 18:44:08.880546 140615978522496 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0409 18:44:08.881845 140615978522496 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0409 18:44:12.239354 140615978522496 monitored_session.py:240] Graph was finalized.\n","2020-04-09 18:44:12.239738: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2020-04-09 18:44:12.243966: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-09 18:44:12.244144: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2493d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-09 18:44:12.244172: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-09 18:44:12.246105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-09 18:44:12.383600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:44:12.384308: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2493b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-09 18:44:12.384340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-04-09 18:44:12.384530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:44:12.385060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-04-09 18:44:12.385372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:44:12.389534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-04-09 18:44:12.391279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-04-09 18:44:12.391637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-04-09 18:44:12.392932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-04-09 18:44:12.393895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-04-09 18:44:12.396861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:44:12.396975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:44:12.397510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:44:12.397995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-04-09 18:44:12.398054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:44:12.399209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-09 18:44:12.399235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-04-09 18:44:12.399245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-04-09 18:44:12.399356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:44:12.399898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:44:12.400393: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-09 18:44:12.400431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-8815\n","I0409 18:44:12.402558 140615978522496 saver.py:1284] Restoring parameters from training/model.ckpt-8815\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0409 18:44:14.566844 140615978522496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0409 18:44:15.621160 140615978522496 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0409 18:44:15.940265 140615978522496 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 8815 into training/model.ckpt.\n","I0409 18:44:24.711934 140615978522496 basic_session_run_hooks.py:606] Saving checkpoints for 8815 into training/model.ckpt.\n","2020-04-09 18:44:37.425433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:44:39.425638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","INFO:tensorflow:loss = 1.6100986, step = 8815\n","I0409 18:44:41.735535 140615978522496 basic_session_run_hooks.py:262] loss = 1.6100986, step = 8815\n","INFO:tensorflow:global_step/sec: 1.6179\n","I0409 18:45:43.543433 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.6179\n","INFO:tensorflow:loss = 1.6055391, step = 8915 (61.809 sec)\n","I0409 18:45:43.544719 140615978522496 basic_session_run_hooks.py:260] loss = 1.6055391, step = 8915 (61.809 sec)\n","INFO:tensorflow:global_step/sec: 1.7429\n","I0409 18:46:40.918905 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.7429\n","INFO:tensorflow:loss = 1.4674983, step = 9015 (57.376 sec)\n","I0409 18:46:40.920283 140615978522496 basic_session_run_hooks.py:260] loss = 1.4674983, step = 9015 (57.376 sec)\n","INFO:tensorflow:global_step/sec: 1.73546\n","I0409 18:47:38.540425 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.73546\n","INFO:tensorflow:loss = 1.2540256, step = 9115 (57.621 sec)\n","I0409 18:47:38.541422 140615978522496 basic_session_run_hooks.py:260] loss = 1.2540256, step = 9115 (57.621 sec)\n","INFO:tensorflow:global_step/sec: 1.742\n","I0409 18:48:35.945757 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.742\n","INFO:tensorflow:loss = 2.6329973, step = 9215 (57.405 sec)\n","I0409 18:48:35.946701 140615978522496 basic_session_run_hooks.py:260] loss = 2.6329973, step = 9215 (57.405 sec)\n","INFO:tensorflow:global_step/sec: 1.73179\n","I0409 18:49:33.689442 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.73179\n","INFO:tensorflow:loss = 1.4178209, step = 9315 (57.744 sec)\n","I0409 18:49:33.690645 140615978522496 basic_session_run_hooks.py:260] loss = 1.4178209, step = 9315 (57.744 sec)\n","INFO:tensorflow:global_step/sec: 1.72388\n","I0409 18:50:31.698050 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.72388\n","INFO:tensorflow:loss = 1.3166096, step = 9415 (58.008 sec)\n","I0409 18:50:31.699104 140615978522496 basic_session_run_hooks.py:260] loss = 1.3166096, step = 9415 (58.008 sec)\n","INFO:tensorflow:global_step/sec: 1.72385\n","I0409 18:51:29.708173 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.72385\n","INFO:tensorflow:loss = 1.5084372, step = 9515 (58.010 sec)\n","I0409 18:51:29.709377 140615978522496 basic_session_run_hooks.py:260] loss = 1.5084372, step = 9515 (58.010 sec)\n","INFO:tensorflow:global_step/sec: 1.75089\n","I0409 18:52:26.821650 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.75089\n","INFO:tensorflow:loss = 1.3937162, step = 9615 (57.114 sec)\n","I0409 18:52:26.822961 140615978522496 basic_session_run_hooks.py:260] loss = 1.3937162, step = 9615 (57.114 sec)\n","INFO:tensorflow:global_step/sec: 1.72522\n","I0409 18:53:24.785141 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.72522\n","INFO:tensorflow:loss = 1.5826173, step = 9715 (57.963 sec)\n","I0409 18:53:24.786358 140615978522496 basic_session_run_hooks.py:260] loss = 1.5826173, step = 9715 (57.963 sec)\n","INFO:tensorflow:global_step/sec: 1.72696\n","I0409 18:54:22.690289 140615978522496 basic_session_run_hooks.py:692] global_step/sec: 1.72696\n","INFO:tensorflow:loss = 1.2709098, step = 9815 (57.905 sec)\n","I0409 18:54:22.691474 140615978522496 basic_session_run_hooks.py:260] loss = 1.2709098, step = 9815 (57.905 sec)\n","INFO:tensorflow:Saving checkpoints for 9824 into training/model.ckpt.\n","I0409 18:54:27.309478 140615978522496 basic_session_run_hooks.py:606] Saving checkpoints for 9824 into training/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0409 18:54:27.413318 140615978522496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Calling model_fn.\n","I0409 18:54:29.520598 140615978522496 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:31.516924 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:31.555592 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:31.589684 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:31.619638 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:31.648693 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:31.678328 140615978522496 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0409 18:54:32.304359 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0409 18:54:32.492544 140615978522496 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0409 18:54:32.776809 140615978522496 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0409 18:54:33.043062 140615978522496 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-04-09T18:54:33Z\n","I0409 18:54:33.060394 140615978522496 evaluation.py:255] Starting evaluation at 2020-04-09T18:54:33Z\n","INFO:tensorflow:Graph was finalized.\n","I0409 18:54:33.453749 140615978522496 monitored_session.py:240] Graph was finalized.\n","2020-04-09 18:54:33.454872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:33.455318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-04-09 18:54:33.455411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:54:33.455440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-04-09 18:54:33.455462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-04-09 18:54:33.455488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-04-09 18:54:33.455521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-04-09 18:54:33.455542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-04-09 18:54:33.455564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:54:33.455640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:33.456136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:33.456517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-04-09 18:54:33.456560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-09 18:54:33.456574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-04-09 18:54:33.456582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-04-09 18:54:33.456668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:33.457123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:33.457517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-9824\n","I0409 18:54:33.458810 140615978522496 saver.py:1284] Restoring parameters from training/model.ckpt-9824\n","INFO:tensorflow:Running local_init_op.\n","I0409 18:54:34.357071 140615978522496 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0409 18:54:34.490185 140615978522496 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 75 images.\n","I0409 18:54:40.531023 140613485344512 coco_evaluation.py:205] Performing evaluation on 75 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0409 18:54:40.532458 140613485344512 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0409 18:54:40.533280 140613485344512 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","2020-04-09 18:54:40.535926: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 176, in __init__\n","    iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n","    session.run(eval_ops, feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n","    raise six.reraise(*original_exc_info)\n","  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n","    raise value\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n","\t [[node IteratorGetNext (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","\n","Original stack trace for 'IteratorGetNext':\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 109, in <module>\n","    tf.app.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 105, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n","    run_metadata=run_metadata))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n","    if self._save(run_context.session, global_step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n","    if l.after_save(session, step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n","    self._evaluate(global_step_value)  # updates self.eval_result\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n","    self._evaluator.evaluate_and_export())\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n","    hooks=self._eval_spec.hooks)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n","    name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n","    return _evaluate()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n","    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n","    self._call_model_fn_eval(input_fn, self.config))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _call_model_fn_eval\n","    input_fn, ModeKeys.EVAL)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n","    self._call_input_fn(input_fn, mode))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\n","    result = iterator.get_next()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\n","    name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\n","    output_shapes=output_shapes, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n","  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 176, in __init__\n","    iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[{{node PyFunc_3}}]]\n","\t [[cond_6/Const/_2581]]\n","  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 176, in __init__\n","    iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[{{node PyFunc_3}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/gun_detection/models/research/object_detection/model_main.py\", line 109, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/gun_detection/models/research/object_detection/model_main.py\", line 105, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n","    raise six.reraise(*original_exc_info)\n","  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n","    raise value\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n","    run_metadata=run_metadata))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n","    if self._save(run_context.session, global_step):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n","    if l.after_save(session, step):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n","    self._evaluate(global_step_value)  # updates self.eval_result\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n","    self._evaluator.evaluate_and_export())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n","    hooks=self._eval_spec.hooks)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n","    name=name)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n","    return _evaluate()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _evaluate\n","    output_dir=self.eval_dir(name))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1619, in _evaluate_run\n","    config=self._session_config)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n","    session.run(eval_ops, feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 861, in __exit__\n","    self._close_internal(exception_type)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 894, in _close_internal\n","    h.end(self._coordinated_creator.tf_sess)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 951, in end\n","    self._final_ops, feed_dict=self._final_ops_feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n","  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 176, in __init__\n","    iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[node PyFunc_3 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[cond_6/Const/_2581]]\n","  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 176, in __init__\n","    iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[node PyFunc_3 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'PyFunc_3':\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 109, in <module>\n","    tf.app.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 105, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n","    run_metadata=run_metadata))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n","    if self._save(run_context.session, global_step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n","    if l.after_save(session, step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n","    self._evaluate(global_step_value)  # updates self.eval_result\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n","    self._evaluator.evaluate_and_export())\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n","    hooks=self._eval_spec.hooks)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n","    name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n","    return _evaluate()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n","    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n","    self._call_model_fn_eval(input_fn, self.config))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1547, in _call_model_fn_eval\n","    features, labels, ModeKeys.EVAL, config)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n","    model_fn_results = self._model_fn(features=features, **kwargs)\n","  File \"content/gun_detection/models/research/object_detection/model_lib.py\", line 482, in model_fn\n","    eval_config, list(category_index.values()), eval_dict)\n","  File \"content/gun_detection/models/research/object_detection/eval_util.py\", line 947, in get_eval_metric_ops_for_evaluators\n","    eval_dict))\n","  File \"content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 394, in get_estimator_eval_metric_ops\n","    first_value_op = tf.py_func(first_value_func, [], tf.float32)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 513, in py_func\n","    return py_func_common(func, inp, Tout, stateful, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 495, in py_func_common\n","    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 318, in _internal_py_func\n","    input=inp, token=token, Tout=Tout, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_script_ops.py\", line 170, in py_func\n","    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5V39_McGX8kg","colab_type":"code","outputId":"e799da2d-cc82-4b23-c2e6-5db18ffaaba3","executionInfo":{"status":"ok","timestamp":1586241782658,"user_tz":-330,"elapsed":25605,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":411}},"source":["!zip -r /content/training.zip /content/gun_detection/models/research/training"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  adding: content/gun_detection/models/research/training/ (stored 0%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-1203.meta (deflated 93%)\n","  adding: content/gun_detection/models/research/training/events.out.tfevents.1586239546.60179eb1d280 (deflated 93%)\n","  adding: content/gun_detection/models/research/training/events.out.tfevents.1586238844.60179eb1d280 (deflated 93%)\n","  adding: content/gun_detection/models/research/training/events.out.tfevents.1586240991.60179eb1d280 (deflated 93%)\n","  adding: content/gun_detection/models/research/training/checkpoint (deflated 73%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-0.index (deflated 77%)\n","  adding: content/gun_detection/models/research/training/graph.pbtxt (deflated 97%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-1605.meta (deflated 93%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-1605.data-00000-of-00001 (deflated 8%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-0.meta (deflated 93%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-400.index (deflated 72%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-1203.index (deflated 72%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-1203.data-00000-of-00001 (deflated 7%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-812.meta (deflated 93%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-400.meta (deflated 93%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-812.index (deflated 72%)\n","  adding: content/gun_detection/models/research/training/events.out.tfevents.1586240266.60179eb1d280 (deflated 93%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-1605.index (deflated 72%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-812.data-00000-of-00001 (deflated 7%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-0.data-00000-of-00001 (deflated 54%)\n","  adding: content/gun_detection/models/research/training/model.ckpt-400.data-00000-of-00001 (deflated 7%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"alnn9wWJYQ8b","colab_type":"code","outputId":"c053ae7f-e61b-4aee-9e66-c4b21660e662","executionInfo":{"status":"ok","timestamp":1586241948861,"user_tz":-330,"elapsed":123982,"user":{"displayName":"sdl project","photoUrl":"","userId":"05844979206698871795"}},"colab":{"base_uri":"https://localhost:8080/","height":462}},"source":["from google.colab import files\n","files.download(\"/content/training.zip\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------------------\n","Exception happened during processing of request from ('::ffff:127.0.0.1', 44186, 0, 0)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n","    self.process_request(request, client_address)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n","    self.finish_request(request, client_address)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n","    self.RequestHandlerClass(request, client_address, self)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n","    self.handle()\n","  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n","    self.handle_one_request()\n","  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n","    method()\n","  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n","    self.copyfile(f, self.wfile)\n","  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n","    shutil.copyfileobj(source, outputfile)\n","  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n","    fdst.write(buf)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 803, in write\n","    self._sock.sendall(b)\n","ConnectionResetError: [Errno 104] Connection reset by peer\n","----------------------------------------\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RPN8liiQc7Ue","colab_type":"text"},"source":["## Exporting The Trained model\n","\n"]},{"cell_type":"code","metadata":{"id":"upwUdom0lTub","colab_type":"code","outputId":"5e1da494-88d0-4c86-8bf2-1c48fe585206","executionInfo":{"status":"ok","timestamp":1586458503823,"user_tz":-330,"elapsed":16414,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","\n","#the location where the exported model will be saved in.\n","output_directory = '/content/gun_detection/models/research/fine_tuned_model'\n","\n","# goes through the model is the training/ dir and gets the last one.\n","# you could choose a specfic one instead of the last\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","\n","#exports the model specifed and inference graph\n","!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={model_pipline} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":43,"outputs":[{"output_type":"stream","text":["training/model.ckpt-9824\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0409 18:54:53.054151 140179759028096 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0409 18:54:53.060124 140179759028096 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0409 18:54:53.089112 140179759028096 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0409 18:54:53.116230 140179759028096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0409 18:54:55.110202 140179759028096 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:55.110435 140179759028096 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:55.147498 140179759028096 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:55.183065 140179759028096 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:55.217315 140179759028096 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:55.252174 140179759028096 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0409 18:54:55.286979 140179759028096 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0409 18:54:55.647820 140179759028096 deprecation.py:323] From /content/gun_detection/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0409 18:54:55.946863 140179759028096 deprecation.py:323] From /content/gun_detection/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0409 18:54:55.949809 140179759028096 deprecation.py:323] From /content/gun_detection/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0409 18:54:55.950767 140179759028096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","133 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.57m params)\n","  BoxPredictor_0 (--/10.39k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/3.46k params)\n","      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n","  BoxPredictor_1 (--/46.12k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/15.37k params)\n","      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n","  BoxPredictor_2 (--/18.47k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/6.16k params)\n","      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","  BoxPredictor_3 (--/9.25k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/3.08k params)\n","      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_4 (--/9.25k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/3.08k params)\n","      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_5 (--/4.64k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/1.55k params)\n","      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","133 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.71k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0409 18:54:56.869681 140179759028096 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","2020-04-09 18:54:57.563797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-09 18:54:57.599442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.600049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-04-09 18:54:57.600345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:54:57.601547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-04-09 18:54:57.602687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-04-09 18:54:57.603042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-04-09 18:54:57.604662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-04-09 18:54:57.605726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-04-09 18:54:57.609413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:54:57.609546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.610124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.610612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-04-09 18:54:57.610961: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2020-04-09 18:54:57.615537: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-09 18:54:57.615710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eacd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-09 18:54:57.615735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-09 18:54:57.726586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.727246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eacf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-09 18:54:57.727277: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-04-09 18:54:57.727455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.727992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-04-09 18:54:57.728067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:54:57.728103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-04-09 18:54:57.728125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-04-09 18:54:57.728149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-04-09 18:54:57.728166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-04-09 18:54:57.728185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-04-09 18:54:57.728214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:54:57.728289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.728846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.729321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-04-09 18:54:57.729396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:54:57.730504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-09 18:54:57.730530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-04-09 18:54:57.730540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-04-09 18:54:57.730643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.731197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:57.731687: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-09 18:54:57.731724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-9824\n","I0409 18:54:57.733409 140179759028096 saver.py:1284] Restoring parameters from training/model.ckpt-9824\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0409 18:54:59.400652 140179759028096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-04-09 18:54:59.875036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:59.875595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-04-09 18:54:59.875690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:54:59.875718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-04-09 18:54:59.875736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-04-09 18:54:59.875766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-04-09 18:54:59.875806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-04-09 18:54:59.875835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-04-09 18:54:59.875855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:54:59.875943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:59.876470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:59.877030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-04-09 18:54:59.877077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-09 18:54:59.877106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-04-09 18:54:59.877117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-04-09 18:54:59.877220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:59.877845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:54:59.878573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-9824\n","I0409 18:54:59.880378 140179759028096 saver.py:1284] Restoring parameters from training/model.ckpt-9824\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0409 18:55:00.438510 140179759028096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0409 18:55:00.438771 140179759028096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 324 variables.\n","I0409 18:55:00.764742 140179759028096 graph_util_impl.py:334] Froze 324 variables.\n","INFO:tensorflow:Converted 324 variables to const ops.\n","I0409 18:55:00.839959 140179759028096 graph_util_impl.py:394] Converted 324 variables to const ops.\n","2020-04-09 18:55:00.968769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:55:00.969348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-04-09 18:55:00.969442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-04-09 18:55:00.969469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-04-09 18:55:00.969487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-04-09 18:55:00.969506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-04-09 18:55:00.969541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-04-09 18:55:00.969559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-04-09 18:55:00.969579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-09 18:55:00.969662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:55:00.970252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:55:00.970728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-04-09 18:55:00.970769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-09 18:55:00.970798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-04-09 18:55:00.970808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-04-09 18:55:00.970909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:55:00.971438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-09 18:55:00.971938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0409 18:55:01.310709 140179759028096 module_wrapper.py:137] From /content/gun_detection/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","Traceback (most recent call last):\n","  File \"/content/gun_detection/models/research/object_detection/export_inference_graph.py\", line 162, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/gun_detection/models/research/object_detection/export_inference_graph.py\", line 158, in main\n","    write_inference_graph=FLAGS.write_inference_graph)\n","  File \"/content/gun_detection/models/research/object_detection/exporter.py\", line 510, in export_inference_graph\n","    write_inference_graph=write_inference_graph)\n","  File \"/content/gun_detection/models/research/object_detection/exporter.py\", line 466, in _export_inference_graph\n","    placeholder_tensor, outputs)\n","  File \"/content/gun_detection/models/research/object_detection/exporter.py\", line 306, in write_saved_model\n","    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\", line 436, in __init__\n","    super(SavedModelBuilder, self).__init__(export_dir=export_dir)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\", line 103, in __init__\n","    \"specified directory: %s\" % export_dir)\n","AssertionError: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: /content/gun_detection/models/research/fine_tuned_model/saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yuxDnGPM_JPL","colab_type":"code","colab":{}},"source":["#downloads the frozen model that is needed for inference\n","files.download(output_directory + '/frozen_inference_graph.pb')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTkkaGq5BpYi","colab_type":"code","outputId":"a162277f-ba1b-442a-dbc9-662f49d9869e","executionInfo":{"status":"error","timestamp":1586458745342,"user_tz":-330,"elapsed":2036,"user":{"displayName":"Praneet Avhad","photoUrl":"","userId":"11641365352815720975"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["#downlaod the label map\n","files.download(DATA_BASE_PATH + '/label_map.pbtxt')"],"execution_count":46,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-1e59a835fe48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_BASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/label_map.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'DATA_BASE_PATH' is not defined"]}]},{"cell_type":"code","metadata":{"id":"AWr3WwzHL2vC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}